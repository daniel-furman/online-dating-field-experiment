{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tinder_experiment_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tinder experiment analysis\n",
        "\n",
        "---\n",
        "\n",
        "* the treatment effect metric employed is the percentage decrease in conversion rate from the Princeton profile to the Rutgers profile, \"the percentage decrease metric\"\n",
        "* bootstrap resampling employed to generate a list of the percentage decrease metrics for females matching male profiles, \"df_male_full\", and for males matching female profiles, \"df_female_full\"\n",
        "* tests, null is difference is explained by chance, alternative is percentage decrease is higher for females matching males than for males matching females (females care more about academic prestige on Tinder than males)\n",
        "  * one-sided t test \n",
        "  * one-sided permutation test\n",
        "  * cohen's d effect size"
      ],
      "metadata": {
        "id": "rctirBEjjMGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eGcdgCYjMNE",
        "outputId": "da91112a-10e5-4207-bb43-7dc5f0ee64c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import choices, shuffle\n",
        "import pandas as pd\n",
        "from statistics import mean, stdev\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "import time\n"
      ],
      "metadata": {
        "id": "pO_fm1I-QlHg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap(ground_truth, predictions, metric, B, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    helper function for providing bootstrap resampling\n",
        "    \n",
        "        ground_truth / predictions: ground truthed labels / model predictions\n",
        "        metric: metric to generate confidence interval for\n",
        "        B: number of iterations\n",
        "        confidence_level: percentage confidence interval desired (default is 2 sigma)\n",
        "    \"\"\"\n",
        "    \n",
        "    # compute lower and upper significance index\n",
        "    critical_value=(1-confidence_level)/2\n",
        "    lower_sig=100*critical_value\n",
        "    upper_sig=100*(1-critical_value)\n",
        "    data=[]\n",
        "    for g, p in zip(ground_truth, predictions):\n",
        "        data.append([g,p])\n",
        "\n",
        "    accuracies=[]\n",
        "    # bootstrap resampling loop\n",
        "    for b in range(B):\n",
        "        choice=choices(data, k=len(data))\n",
        "        choice=np.array(choice)\n",
        "        accuracy=metric(choice[:,0], choice[:,1])\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "    \n",
        "    #percentiles=np.percentile(accuracies, [lower_sig, 50, upper_sig])\n",
        "    \n",
        "    #lower=percentiles[0]\n",
        "    #median=percentiles[1]\n",
        "    #upper=percentiles[2]\n",
        "    \n",
        "    return accuracies"
      ],
      "metadata": {
        "id": "D0D_533LQlag"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_decrease_metric(princeton, rutgers):\n",
        "  # grab outcomes for each group\n",
        "\n",
        "  printeton_outcomes = princeton\n",
        "  rutgers_outcomes = rutgers\n",
        "\n",
        "  # grab conversion rate for each group\n",
        "  princeton_matches = printeton_outcomes[printeton_outcomes==1] \n",
        "  princeton_conversion_rate = len(princeton_matches)/len(printeton_outcomes)\n",
        "\n",
        "  rutgers_matches = rutgers_outcomes[rutgers_outcomes==1] \n",
        "  rutgers_conversion_rate = len(rutgers_matches)/len(rutgers_outcomes)\n",
        "\n",
        "  # grab percentage increase from rutgers to princeton\n",
        "  percentage_decrease = ((princeton_conversion_rate - rutgers_conversion_rate)/(princeton_conversion_rate)) * 100\n",
        "  return percentage_decrease"
      ],
      "metadata": {
        "id": "re_J63Z8QmET"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "\n",
        "df_female_full = pd.read_csv('https://raw.githubusercontent.com/daniel-furman/online-dating-field-experiment/main/data/processed_data/df_female_full.csv', index_col='Unnamed: 0')\n",
        "# shuffle the data\n",
        "df_female_full = df_female_full.sample(frac=1)\n",
        "print(df_female_full.head())\n",
        "\n",
        "df_male_full = pd.read_csv('https://raw.githubusercontent.com/daniel-furman/online-dating-field-experiment/main/data/processed_data/df_male_full_2.csv', index_col='Unnamed: 0')\n",
        "# shuffle the data\n",
        "df_male_full = df_male_full.sample(frac=1)\n",
        "print('\\n', df_male_full.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPlwk5w-RKAs",
        "outputId": "926743ef-bc92-4e32-a330-2c79dc11a22f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Name  Age  School  Work  Match  Treatment\n",
            "7    Squid game   30       1     1      1          0\n",
            "144       Peter   26       1     1      1          1\n",
            "6          Alex   28       0     0      1          0\n",
            "63          Joe   29       1     0      0          0\n",
            "54      Michael   23       1     0      0          0\n",
            "\n",
            "           Name  Age  School  Work  Match  Treatment\n",
            "201      Katya   24       0     0      0          1\n",
            "170     Hannah   24       0     0      0          1\n",
            "39     Nichole   24       0     0      0          0\n",
            "122  Dominique   26       0     0      1          1\n",
            "196     Ashley   21       1     0      0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "female_list = bootstrap(df_female_full[df_female_full['Treatment']==1]['Match'],\n",
        "                   df_female_full[df_female_full['Treatment']==0]['Match'],\n",
        "                   percentage_decrease_metric,\n",
        "                   100,)\n",
        "np.mean(female_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s63QbevMZlzv",
        "outputId": "849e552d-b27e-4ec4-ebd0-ebe047f40041"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.10402566077028"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_list = bootstrap(df_male_full[df_male_full['Treatment']==1]['Match'],\n",
        "                           df_male_full[df_male_full['Treatment']==0]['Match'],\n",
        "                           percentage_decrease_metric,\n",
        "                           100,)\n",
        "np.mean(male_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83zox9Fav3V",
        "outputId": "209fd99e-48ee-408e-e145-eac5375784f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.05214885004938"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# t testing\n",
        "# Null is that the mean percentage decrease from princeton to rutgers is the same between the two groups.\n",
        "# Alternative is that the mean percentage decrease from princeton to rutgers is larger for females matching men.\n",
        "\n",
        "p_val_list = []\n",
        "for i in range(0,1000):\n",
        "    male_bootstrap = pd.Series(male_list).sample(frac=1, replace=True).to_list()\n",
        "    female_bootstrap = pd.Series(female_list).sample(frac=1, replace=True).to_list()\n",
        "    p_val = stats.ttest_ind(male_bootstrap, female_bootstrap, equal_var=False, alternative='greater')[1]\n",
        "    p_val_list.append(p_val)\n",
        "\n",
        "p_val_list.sort()\n",
        "lower = p_val_list[25]\n",
        "median = p_val_list[500]\n",
        "upper = p_val_list[975]\n",
        "\n",
        "print(f\"\\nP_val for Welch's T-test: {median}, with a 95% confidence interval of [{lower},{upper}]\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o5HSw1qXdJX",
        "outputId": "a141313e-2c57-4b7c-c1d2-0a07fcad91ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "P_val for Welch's T-test: 1.1591479232274766e-21, with a 95% confidence interval of [2.450539342435309e-29,4.0696522426785225e-15]\n",
            "\n",
            "CPU times: user 1.04 s, sys: 22.8 ms, total: 1.06 s\n",
            "Wall time: 1.04 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# practical significance testing\n",
        "def cohens_d(list1, list2): # with correction for small sample\n",
        "    return (mean(list1) - mean(list2)) / (sqrt((stdev(list1) ** 2 + stdev(list2) ** 2) / 2)) * ((len(list1)- 3)/ (len(list1)- 2.25)) * sqrt(((len(list1)- 2)/len(list1)))\n",
        "\n",
        "print(\"Effect size, Cohens D (number of strandard deviations between distributions): \", cohens_d(male_list, female_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLEX-6XXdMM",
        "outputId": "e1acf285-7237-4c7e-bd7c-67656faf166f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effect size, Cohens D (number of strandard deviations between distributions):  1.4898754415873396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Non-parametric testing (permutation testing) on median\n",
        "# Null is that the median percentage decrease from princeton to rutgers is explained by chance between the two groups.\n",
        "# Alternative is that the median percentage decrease from princeton to rutgers is larger for females matching men.\n",
        "\n",
        "\n",
        "# Testing on median\n",
        "p_val_list = []\n",
        "permutation_iters = 3000\n",
        "ground_truth = np.median(male_list) - np.median(female_list)\n",
        "# pool variables into one distribution, sample two distributions equal in size to the original \n",
        "pooled = list(male_list+female_list)\n",
        "for i in range(0,1000):\n",
        "    permuted_differences = []\n",
        "    for i in range(0,permutation_iters):    \n",
        "        shuffle(pooled)\n",
        "        permuted_differences.append(np.median(pooled[0:int(len(pooled)/2)]) - np.median(pooled[int(len(pooled)/2):]))\n",
        "    p_val = len(np.where(permuted_differences>=ground_truth)[0])/permutation_iters\n",
        "    p_val_list.append(p_val)\n",
        "p_val_list.sort()\n",
        "lower = p_val_list[25]\n",
        "median = p_val_list[500]\n",
        "upper = p_val_list[975]\n",
        "print(f'\\nP_val for One-Tailed Permutation Test of Mean: {median}, with a 95% confidence interval of [{lower},{upper}]\\n')"
      ],
      "metadata": {
        "id": "Wht-rdTfXUs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761f3a49-006c-4c39-a2ec-fe0fd11774e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "P_val for One-Tailed Permutation Test of Mean: 0.0, with a 95% confidence interval of [0.0,0.0]\n",
            "\n",
            "CPU times: user 11min 49s, sys: 2.42 s, total: 11min 51s\n",
            "Wall time: 11min 49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d-IM4A0lfOBV"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}