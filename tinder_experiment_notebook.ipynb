{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tinder_experiment_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tinder experiment analysis\n",
        "\n",
        "---\n",
        "\n",
        "* the treatment effect metric employed is the percentage decrease in conversion rate from the Princeton profile to the Rutgers profile, \"the percentage decrease metric\"\n",
        "* bootstrap resampling employed to generate a list of the percentage decrease metrics for females matching male profiles, \"df_male_full\", and for males matching female profiles, \"df_female_full\"\n",
        "* tests, null is difference is explained by chance, alternative is percentage decrease is higher for females matching males than for males matching females (females care more about academic prestige on Tinder than males)\n",
        "  * one-sided t test \n",
        "  * one-sided permutation test\n",
        "  * cohen's d effect size"
      ],
      "metadata": {
        "id": "rctirBEjjMGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eGcdgCYjMNE",
        "outputId": "1031b0fa-505d-49f4-9d27-44b0d041f10d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import choices, shuffle\n",
        "import pandas as pd\n",
        "from statistics import mean, stdev\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "import time\n"
      ],
      "metadata": {
        "id": "pO_fm1I-QlHg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap(ground_truth, predictions, metric, B, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    helper function for providing bootstrap resampling\n",
        "    \n",
        "        ground_truth / predictions: ground truthed labels / model predictions\n",
        "        metric: metric to generate confidence interval for\n",
        "        B: number of iterations\n",
        "        confidence_level: percentage confidence interval desired (default is 2 sigma)\n",
        "    \"\"\"\n",
        "    \n",
        "    # compute lower and upper significance index\n",
        "    critical_value=(1-confidence_level)/2\n",
        "    lower_sig=100*critical_value\n",
        "    upper_sig=100*(1-critical_value)\n",
        "    data=[]\n",
        "    for g, p in zip(ground_truth, predictions):\n",
        "        data.append([g,p])\n",
        "\n",
        "    accuracies=[]\n",
        "    # bootstrap resampling loop\n",
        "    for b in range(B):\n",
        "        choice=choices(data, k=len(data))\n",
        "        choice=np.array(choice)\n",
        "        accuracy=metric(choice[:,0], choice[:,1])\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "    \n",
        "    #percentiles=np.percentile(accuracies, [lower_sig, 50, upper_sig])\n",
        "    \n",
        "    #lower=percentiles[0]\n",
        "    #median=percentiles[1]\n",
        "    #upper=percentiles[2]\n",
        "    \n",
        "    return accuracies"
      ],
      "metadata": {
        "id": "D0D_533LQlag"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_decrease_metric(princeton, rutgers):\n",
        "  # grab outcomes for each group\n",
        "\n",
        "  printeton_outcomes = princeton\n",
        "  rutgers_outcomes = rutgers\n",
        "\n",
        "  # grab conversion rate for each group\n",
        "  princeton_matches = printeton_outcomes[printeton_outcomes==1] \n",
        "  princeton_conversion_rate = len(princeton_matches)/len(printeton_outcomes)\n",
        "\n",
        "  rutgers_matches = rutgers_outcomes[rutgers_outcomes==1] \n",
        "  rutgers_conversion_rate = len(rutgers_matches)/len(rutgers_outcomes)\n",
        "\n",
        "  # grab percentage increase from rutgers to princeton\n",
        "  percentage_decrease = ((princeton_conversion_rate - rutgers_conversion_rate)/(princeton_conversion_rate)) * 100\n",
        "  return percentage_decrease"
      ],
      "metadata": {
        "id": "re_J63Z8QmET"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "\n",
        "df_female_full = pd.read_csv('https://raw.githubusercontent.com/daniel-furman/online-dating-field-experiment/main/data/processed_data/df_female_full.csv', index_col='Unnamed: 0')\n",
        "# shuffle the data\n",
        "df_female_full = df_female_full.sample(frac=1)\n",
        "print(df_female_full.head())\n",
        "\n",
        "df_male_full = pd.read_csv('https://raw.githubusercontent.com/daniel-furman/online-dating-field-experiment/main/data/processed_data/df_male_full_2.csv', index_col='Unnamed: 0')\n",
        "# shuffle the data\n",
        "df_male_full = df_male_full.sample(frac=1)\n",
        "print('\\n', df_male_full.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPlwk5w-RKAs",
        "outputId": "9ae74dce-6024-4845-fe93-e0dea776a3a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name  Age  School  Work  Match  Treatment\n",
            "77   Jerico   26       1     1      0          0\n",
            "106    Joey   26       0     1      1          1\n",
            "112   Galen   22       0     0      1          1\n",
            "184    Nate   23       0     0      0          1\n",
            "43     John   22       0     1      0          0\n",
            "\n",
            "           Name  Age  School  Work  Match  Treatment\n",
            "170     Hannah   24       0     0      0          1\n",
            "59      Monica   27       0     1      0          0\n",
            "89        Anne   26       1     1      0          0\n",
            "150  Libbyanna   23       1     1      0          1\n",
            "115     Teresa   23       0     0      1          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "female_list = bootstrap(df_female_full[df_female_full['Treatment']==1]['Match'],\n",
        "                   df_female_full[df_female_full['Treatment']==0]['Match'],\n",
        "                   percentage_decrease_metric,\n",
        "                   100,)\n",
        "np.mean(female_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s63QbevMZlzv",
        "outputId": "348634dd-2d4e-4fe6-dd6e-7ea6d9a87adc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.743826264699"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_list = bootstrap(df_male_full[df_male_full['Treatment']==1]['Match'],\n",
        "                           df_male_full[df_male_full['Treatment']==0]['Match'],\n",
        "                           percentage_decrease_metric,\n",
        "                           100,)\n",
        "np.mean(male_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83zox9Fav3V",
        "outputId": "73ed3beb-73fd-4ba9-d640-865f536e7057"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.5214703983703"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# t testing\n",
        "# Null is that the mean percentage decrease from princeton to rutgers is the same between the two groups.\n",
        "# Alternative is that the mean percentage decrease from princeton to rutgers is larger for females matching men.\n",
        "\n",
        "p_val_list = []\n",
        "for i in range(0,1000):\n",
        "    male_bootstrap = pd.Series(male_list).sample(frac=1, replace=True).to_list()\n",
        "    female_bootstrap = pd.Series(female_list).sample(frac=1, replace=True).to_list()\n",
        "    p_val = stats.ttest_ind(male_bootstrap, female_bootstrap, equal_var=False, alternative='greater')[1]\n",
        "    p_val_list.append(p_val)\n",
        "\n",
        "p_val_list.sort()\n",
        "lower = p_val_list[25]\n",
        "median = p_val_list[500]\n",
        "upper = p_val_list[975]\n",
        "\n",
        "print(f\"\\nP_val for Welch's T-test: {median}, with a 95% confidence interval of [{lower},{upper}]\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o5HSw1qXdJX",
        "outputId": "7a95d5d2-eee1-4b1c-c70b-0fe6888af5c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "P_val for Welch's T-test: 7.967108023031416e-24, with a 95% confidence interval of [7.373428917129313e-33,3.8935860133228996e-17]\n",
            "\n",
            "CPU times: user 914 ms, sys: 25.2 ms, total: 939 ms\n",
            "Wall time: 911 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# practical significance testing\n",
        "def cohens_d(list1, list2): # with correction for small sample\n",
        "    return (mean(list1) - mean(list2)) / (sqrt((stdev(list1) ** 2 + stdev(list2) ** 2) / 2)) * ((len(list1)- 3)/ (len(list1)- 2.25)) * sqrt(((len(list1)- 2)/len(list1)))\n",
        "\n",
        "print(\"Effect size, Cohens D (number of strandard deviations between distributions): \", cohens_d(male_list, female_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLEX-6XXdMM",
        "outputId": "b48c4734-6cf0-4433-91f6-812c5aaa9876"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effect size, Cohens D (number of strandard deviations between distributions):  1.6207253823929082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Non-parametric testing (permutation testing) on median\n",
        "# Null is that the median percentage decrease from princeton to rutgers is explained by chance between the two groups.\n",
        "# Alternative is that the median percentage decrease from princeton to rutgers is larger for females matching men.\n",
        "\n",
        "\n",
        "# Testing on median\n",
        "p_val_list = []\n",
        "permutation_iters = 3000\n",
        "ground_truth = np.median(male_list) - np.median(female_list)\n",
        "# pool variables into one distribution, sample two distributions equal in size to the original \n",
        "pooled = list(male_list+female_list)\n",
        "for i in range(0,1000):\n",
        "    permuted_differences = []\n",
        "    for i in range(0,permutation_iters):    \n",
        "        shuffle(pooled)\n",
        "        permuted_differences.append(np.median(pooled[0:int(len(pooled)/2)]) - np.median(pooled[int(len(pooled)/2):]))\n",
        "    p_val = len(np.where(permuted_differences>=ground_truth)[0])/permutation_iters\n",
        "    p_val_list.append(p_val)\n",
        "p_val_list.sort()\n",
        "lower = p_val_list[25]\n",
        "median = p_val_list[500]\n",
        "upper = p_val_list[975]\n",
        "print(f'\\nP_val for One-Tailed Permutation Test on Median: {median}, with a 95% confidence interval of [{lower},{upper}]\\n')"
      ],
      "metadata": {
        "id": "Wht-rdTfXUs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d-IM4A0lfOBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}